# Game-ab-test-optimization
A statistical analysis project evaluating A/B test results for a mobile application. Utilized Python, Hypothesis Testing, and Bootstrapping to measure Day-1 vs Day-7 retention impact
Mobile App A/B Testing: Optimizing User RetentionğŸ“Œ Project OverviewThis project analyzes the impact of "gate" placement on player retention in a mobile game. Using a dataset of 90,189 players, we performed an A/B test to determine if moving the first "gate" (a level where users are forced to wait or pay) from Level 30 to Level 40 improves retention.Business Goal: Increase the Lifetime Value (LTV) of players by maximizing Day-7 retention.ğŸ“Š The DataSource: Kaggle Mobile Games A/B TestingSample Size: 90,189 unique users.Groups:Control Group (gate_30): Players encounter the gate at Level 30.Test Group (gate_40): Players encounter the gate at Level 40.Metrics:retention_1: Did the player return 1 day after installation?retention_7: Did the player return 7 days after installation?ğŸ›  Tech StackPython: Data cleaning and logic.Pandas: Data manipulation and aggregation.SciPy / Statsmodels: Statistical hypothesis testing (Chi-Square & T-Tests).Bootstrapping: Advanced simulation to validate statistical significance without assuming normal distribution.Seaborn/Matplotlib: Visualization of retention distributions.ğŸ” Key Insights & Results1. Retention RatesGroupDay 1 RetentionDay 7 RetentionGate 30 (Control)44.82%19.02%Gate 40 (Test)44.23%18.20%Observation: The control group (Gate 30) performed slightly better in both metrics.2. Statistical Significance (Bootstrapping)To confirm this wasn't random chance, I performed a Bootstrap Analysis with 1,000 resamples.Result: The probability that retention is higher when the gate is at Level 30 is ~99.9%.Conclusion: There is strong statistical evidence that moving the gate to Level 40 negatively impacts retention.ğŸ“ˆ Visualizations
